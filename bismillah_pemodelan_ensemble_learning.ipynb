{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import math\n",
    "import collections\n",
    "import time\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from IPython.display import display\n",
    "# from sklearn import metrics\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from statistics import stdev\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confussion_matrik(actual,predict):\n",
    "    TP,FP,FN,TN = 0,0,0,0\n",
    "    for i,val in enumerate(actual):\n",
    "        if val == 0:\n",
    "            if val == predict[i]:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        if val == 1:\n",
    "            if val == predict[i]:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    return TP,FP,FN,TN\n",
    " \n",
    "def acc_sens_spec(actual,predict):\n",
    "    TP,FP,FN,TN = confussion_matrik(actual,predict)\n",
    "# akurasi\n",
    "    if (TP+FP+FN+TN) == 0 :\n",
    "        accuracy = 0 \n",
    "    else :\n",
    "        accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        \n",
    "# sensitivity\n",
    "    if (TP+FN) == 0 :\n",
    "        sensitivity = 0\n",
    "    else :\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        \n",
    "# specifity    \n",
    "    if (TN +FP) == 0 :\n",
    "        specifity = 0\n",
    "    else :\n",
    "        specifity = TN/(TN +FP)\n",
    "        \n",
    "# precision\n",
    "    if (TP+FP) == 0 :\n",
    "        precision = 0\n",
    "    else :\n",
    "        precision = TP/(TP+FP)\n",
    "\n",
    "# recall\n",
    "    recall = sensitivity\n",
    "\n",
    "# f1_score\n",
    "    if (precision+recall) == 0 :\n",
    "        f1_score = 0\n",
    "    else :\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))  \n",
    "    \n",
    "    return accuracy,sensitivity,specifity,precision,recall,f1_score\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    #how many correct predictions?\n",
    "    correct = 0\n",
    "    #for each actual label\n",
    "    for i in range(len(actual)):\n",
    "        #if actual matches predicted label\n",
    "        if actual[i] == predicted[i]:\n",
    "            #add 1 to the correct iterator\n",
    "            correct += 1\n",
    "    #return percentage of predictions that were correct\n",
    "    return correct / float(len(actual)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confussion_matrik(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy,sensitivity,specifity = acc_sens_spec(y,pred)\n",
    "# print('acc',accuracy)\n",
    "# print('sens',sensitivity)\n",
    "# print('spec',specifity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# accuracy_metric(y,RF.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_split(X,fold=2,seed=0):\n",
    "    np.random.seed(seed)\n",
    "    n_folds= fold\n",
    "    size = X.shape[0]/n_folds\n",
    "    X_idx = list(range(X.shape[0]))\n",
    "    folds_data= []\n",
    "    for i in range(n_folds):\n",
    "#         print(X_idx)\n",
    "        random_idx = list(np.random.choice(X_idx,int(size),replace=False))\n",
    "#         print(random_idx)\n",
    "        X_idx = [idx for idx in X_idx if idx not in random_idx]\n",
    "#         print(X_idx)\n",
    "\n",
    "        folds_data.append(random_idx)\n",
    "#         print(\"--\")\n",
    "    return folds_data\n",
    "\n",
    "def kfold_cross_validation(model,X,y, n_fold=2, n_seed=0):\n",
    "    folds = cross_val_split(X,fold=n_fold,seed=n_seed)\n",
    "    fold_result =[]\n",
    "    for i in range(len(folds)):\n",
    "    #     print(i)\n",
    "        train = []\n",
    "        for j in range(len(folds)):\n",
    "            if j != i:\n",
    "                train = train + folds[j]\n",
    "        test = folds[i]\n",
    "\n",
    "        X_train = X.iloc[train,:].reset_index(drop=True)\n",
    "        y_train = y[train].reset_index(drop=True)\n",
    "\n",
    "        X_test = X.iloc[test,:].reset_index(drop=True)\n",
    "        y_test = y[test].reset_index(drop=True)\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        waktu = t1 - t0\n",
    "\n",
    "        predict = model.predict(X_test)\n",
    "        accuracy,sensitivity,specifity,precision,recall,f1_score = acc_sens_spec(y_test,predict)\n",
    "\n",
    "        result = [accuracy,sensitivity,specifity,precision,recall,f1_score,waktu]\n",
    "        fold_result.append(result)\n",
    "        \n",
    "    return fold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pylab as pl\n",
    "def plot_this(X_rs,y_rs,method):\n",
    "  # Use principal component to condense the 10 features to 2 features\n",
    "  pca = PCA(n_components=2).fit(X_rs)\n",
    "  pca_2d = pca.transform(X_rs)\n",
    "  # Assign colors\n",
    "  for i in range(0, pca_2d.shape[0]):\n",
    "    if y_rs[i] == 0:\n",
    "      c1 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='r', marker='o')\n",
    "    elif y_rs[i] == 1:\n",
    "      c2 = pl.scatter(pca_2d[i,0],pca_2d[i,1],c='g', marker='*')  \n",
    "  pl.legend([c1, c2], ['Class 1', 'Class 2'])\n",
    "  pl.title(method)\n",
    "  pl.axis([-4, 5, -4, 4])  # x axis (-4,5), y axis (-4,4)\n",
    "  pl.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "##read data\n",
    "\n",
    "df = pd.read_csv('data/creditcard_ulb.csv',sep=\",\")\n",
    "# df = pd.read_csv('data/sample_data.csv',sep=\",\")\n",
    "\n",
    "df0 = df.copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2662cdc4400>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGGCAYAAABVMNdKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XlclWX+//HXAYQjiILLuCfYmDilhkiCuRTppOKSpZVo5jK5IG5MmksalpomagHlNlZqTuOUO2S5tWiilkuOpmOyqcW4hSRw4Mjy+6Of59sJVLiTRX0/Hw8eM+f63Nd9X/d5JG/u695MBQUFBYiIiJSQQ3kPQEREbk8KEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkQqpLy8PFavXs3TTz9N69at8ff3p1+/fmzZssVuueeee47x48eX0yhh3759NG3a1O6nRYsWdO3alejoaHJycmzLnj17lqZNm/LVV18Va92ZmZl88MEHN1zm9+ucNGkSTz/9tPEd+v927NjBqVOnbJ+bNm3Khx9++IfXK3cWp/IegMjvWa1Whg4dyunTpwkLC8PPz4/8/Hw+/fRTwsPDSUhIICwsrLyHaWf16tU0atSIgoICMjMz+fbbb5k/fz6HDh1i2bJlODo6UrduXXbv3k21atWKtc7FixcTFxfHgAEDrrtMSddZHImJiYSGhrJy5Ur+/Oc/A7B7927c3d1v2TbkzqAAkQrnrbfe4tixY2zatIkGDRrY2q+FxjvvvEOPHj1o1KhReQ2xEE9PT2rVqmX77O3tTePGjQkJCWH9+vX06dMHR0dHu2VupjgPiSjpOo1u91ZvQ+4MmsKSCuXq1at8/PHHPPXUU3bhcc2gQYNYsWIFdevWLbL/559/zrPPPouvry8PPPAA3bt3JzY21lb/+eefGTduHAEBATRv3pwnn3ySHTt22OqnT59m2LBh+Pv78+CDD9K/f38OHDhgaF/8/Pzw9fVl8+bNQOHpphuNJTo6mmXLlvHjjz/StGlT9u3bx7p16+jQoQNvvPEGrVu3pl+/fkVOi+Xl5TF37lz8/f1p3bo1r7zyChaLxVYvajoqKCiIyMhIzp49S7du3QAYOHAgkyZNKrLP119/bfueAwICmDJlCpcvX7Zb35IlSxgzZgy+vr488sgjzJw5k9zcXNsy77//Pn/961954IEH6NixI3PnzsVqtRr6rqV8KECkQjlz5gyXL1+mVatWRdarVKmCv78/zs7OhWrHjx8nNDSUoKAgNm3axLp162jatCmTJ0/m0qVLAMyYMYMff/yRd999l08++YQ2bdowZswYfvrpJwDCw8NxcHDgww8/ZMOGDdSpU4cRI0bY/QIuCR8fH06cOFFk7UZjGTJkCAMGDKBOnTrs3r0bX19fAM6dO0diYiLr1q3jlVdeKXK9R48eJSUlhQ8++ICoqCh27dplC4KbqVu3LqtXrwZ+DbGpU6cWWmbnzp0MHTqUNm3asHbtWhYuXMjhw4cZNGiQXUDExMTQqlUr1q9fzwsvvMAHH3xgC/Mvv/ySyMhIXnzxRbZu3cqrr77Kv//9b957771ijVMqBk1hSYWSnp4OYGhO32QyMWXKFJ577jlb27Bhw4iNjSUpKYkaNWqQnJyMh4cHDRo0oGrVqowfP562bdva5veTk5Px9vamQYMGmM1mpk+fzvfff4+Dg7G/tapVq0ZGRkaRtRuNxc3NjcqVKxc5RRUaGso999wD/HpU83uenp5ERkbi6uoKwNSpUwkNDeXMmTM0bNjwhuN1dHTE09PTNvaiznssXryY9u3b2y5eaNy4MQsWLKBXr158/vnndO7cGYCAgAAGDRoEgJeXFx988AEHDx7kiSeeICkpCZPJRN26dalXrx716tXj3XffpWrVqjccn1QsOgKRCqV69eoAdtMhxeXj40Pnzp1Zvnw5kydPZsCAAYSEhAC/TusAjB49miNHjhAYGEhISAjLli3Dy8vL9osyPDycLVu28NBDDzF48GA+/vhjmjRpgouLi6H9uXLlynVPPt9sLNdzs3M/f/nLX2zhAdCyZUsA/vvf/5Zw9EU7efIk/v7+dm0+Pj5UrVrVbhve3t52y7i7u3P16lUAevbsyb333kufPn147LHHmD59Or/88kuhPlKxKUCkQmnYsCE1a9bk4MGDRdavXLnCwIED2b17d6Ha/v37+etf/8o333xDkyZNGDZsGEuXLrVbplOnTuzatYsFCxZw3333sXbtWnr27Mm+ffsACAkJYdeuXbz22mvUqVOHd999lx49ethd0loSx44d4/777y+ydrOxXI/ZbL5h/fdHS/n5+cD/hWhRfjv1dDPX1vd7eXl5VKpUyfa5qGnGayfoq1evzvr161mzZg1PPvkkCQkJvPDCC8yYMaPY45DypwCRCsXBwYE+ffqwbt06fvzxx0L1999/n/3791O/fv1CtXfffZeWLVuyePFihgwZQocOHTh37hzw6y+ugoIC5s+fz3/+8x8ef/xxIiIi2Lp1K56enmzZsoWMjAxmz57NuXPn6NWrF6+//jpbt24lMzOTzz//vMT78t1333H48GF69epVqHazscCvU3JGnDhxwi4svv32WwCaNWsGQKVKleym1TIyMmzniIqz3aZNm/LNN9/YtX3//fdkZmbaLvu9me3bt7N48WIefPBBRo0axerVqxkxYgTr1q0rVn+pGHQORCqckSNHEh8fT79+/Rg3bhx+fn5kZmayceNGVqxYQXh4eJFTHXXr1uWzzz6zBcyhQ4eYPXs28Ou9JSaTiaSkJLZu3cqMGTNo2LAhBw8e5Pz58/j6+lKlShW++eYbDh8+zNSpU6lRowY7duzAarXaTmJfT1paGhcuXKCgoICMjAz27dtHdHQ0HTp0oEePHoWWv9lYANzc3EhPTycxMbHIwLyeS5cuMWHCBIYPH05qaiqzZ8+mS5cutvMmvr6+fPzxxwQEBODi4sKbb76Jk9P//Spwc3MDfp3yuu+++2znRK4ZNmwYYWFhLFy4kF69enHu3Dlee+01mjVrRvv27Ys1RpPJRFRUFK6urgQFBZGWlsZXX3110+9ZKhYFiFQ4ZrOZlStX8t577/Hee+/x2muv4ezsTJMmTYiJiaFTp05F9hszZgyXLl1i1KhR5Ofn4+XlxdSpU3n99dc5cuQIHTp0YNasWcydO5cXX3yRy5cvU79+fSZOnGg7Snj77beZM2cOI0aM4MqVKzRu3Jj58+fTunXrG465f//+tv/v4eFB/fr1GTZsGCEhIdf9i/5mYwkODmbTpk307NmTN954o9jfX4cOHahatSrPPvsszs7O9OjRgxdffNFWj4iIYMaMGYSEhODp6cngwYPt7pivXbs2Tz31FPPmzWPPnj0sXrzYbv2dO3cmOjqaRYsWsXz5cqpWrUqnTp0IDw8vctqqKI899hgzZsxgxYoVLFiwALPZTMeOHYt9tZhUDCa90lZERIzQORARETFEASIiIoYoQERExBAFiIiIGKIAkVK3Z88eBg4caPucmppKaGgofn5+BAQEMHPmTLKzs0u0zqZNm9KrV68iH753K96J8dxzzxV6z8e1n9DQ0D+0bqNu9k6O5557jujo6Ot+vpHk5GR8fX1JSEgo0ZiuPczxej/bt28v0fpuhWvPQLt2Zdm0adNsz/eSW0uX8UqpysjI4OWXX+add94Bfr3jeejQodSuXZvVq1dz4cIFpk6dSlZWlu2ejeI6ceIEb7/9dqm9UOrapaa/Z/SxJhXViRMnGDlyJFlZWYbXMX/+fNq0aVOo/Va+p8So8ePH07NnT9q3b2+7F0ZuDR2BSKlauXIl9957Lz4+PgBs3bqVlJQUIiMj8fHxoX379rzyyiusX7/edtd4cd1zzz0sW7aMI0eOlMbQcXFxoVatWoV+7qQH/i1cuJCnn36aGjVq/KH1VK1atcjvqrj3hZSm6tWr07VrV956663yHsodRwEipcZqtbJq1SqCg4Ntbd988w333Xef3S+sgIAA8vPzbe/duDYFUdSTZn/r+eefx8fHh5deesnuRrjfu3LlCrNnz+bRRx+lefPm9O7dm23btv3Bvft1qiw0NJQXXniBVq1a2W72W7t2LU888QQtW7akRYsW9OnThz179tj6FfUa3t9PuyUkJDB06FDbuzTi4uL+8HiL8tVXX7Fw4UImTJhQZH3SpEkEBQX94e00bdqUN998k8cee4zAwEC+++47rly5wiuvvELHjh25//77adOmDePHjyctLQ24/iuAfz+Vt3btWh5//HGaN2/OgAEDbI/m/63g4GC2bNlS5ONxxDgFiJSaAwcO8PPPP9OxY0db2//+9z/q1Kljt5ybmxtubm6kpqYC0K1bN3bv3n3dl0Zd4+joyNy5czl79izz588vcpn8/HyGDBnCl19+ycyZM9m4cSOPPPIIo0eP5tNPP/2De/jru8NbtmzJhg0b6NevHzt27GD69On079+fuLg4/vnPf1KlShVefPHFYr8s6cqVKzz//PMAfPjhh0RGRha6G/xWWb9+PY899th161OnTuXjjz++JdtavXq1bV8eeOABJk+ezMGDB1m4cCFbt25l5syZ7Nq1i0WLFhV7nZ988gkvv/wyzz77LJs3byY4OJglS5YUWu7BBx+kWrVqhp5pJtencyBSag4dOsSf/vQnu2cpWSyWIufFXVxcbEcRZrP5pk+cvaZJkyaMGTOG+fPn06lTJx566CG7+u7duzly5AgfffQRLVq0AGDs2LGcPHmSd955hy5dulx33Vu3bi30bKZ69erZHQ24uroyatQo2+NKzp07x8yZM+nduzcADRo0YODAgYwcOZJLly7dNBQB4uLiSE9PZ968ebbH28+ZM4cnn3yyGN/IrVXc96CHhYXh6Oho1zZ8+HBGjBhh+xwcHGz3fQYGBhIaGspf/vIXAOrXr8+mTZtK9Nj5FStW0LlzZwYPHgz8+t6RhIQEVq1aVWjZ++67j0OHDt3wHfNSMgoQKTUXLlwoNLduNpuL/Es8JyfH7h0WJTF06FB27NjB5MmT2bRpk13t5MmTuLi40Lx5c7t2f39/du7cSX5+/nVfFtWuXTumTJli1/bbhw7Cr4+f/+2zrlq3bk316tVZtGgRSUlJnD59muPHjwM3fpz678fcsGFDW3gA3H///cUO1fLwyiuvFHpe2O//UPDy8rL73K9fP7744gs2b97M6dOnSUhIIDk5udC7Rm7k5MmThZ6N1qpVqyIDpHr16ly8eLHY65abU4BIqTGZTIXeHVG3bl2+++47u7bMzEwyMzMLTW0Vl4ODA3PnzqVXr17MnTvXrna9d1cUFBTg6Oh4wzcNurq63vTlTb//pR4XF8fEiRPp2rUrLVq0oHfv3qSlpd30SrHfv4+jqEfU/T68KpJatWrd9Lv67dVr+fn5jBw5kmPHjtGzZ086d+7M6NGjeeedd2znQIp6CGVR7y35/Xf123eS/FZeXl6hoyT5Yyruf5Fy26tduzY///yzXZu/vz8fffQRaWlptqmt+Ph4HB0d8fPzM7ytRo0a8eKLL/Laa69xzz332NZ97X6A//znP7YpLPj15VNNmjQxvL3rWbx4MT179uT111+3tS1btgz4v190zs7OhV5zm5KSYvuF2axZM/79739z/vx5/vSnPwGQmJh43Vfj3o6OHz/OF198wapVq2zTjgUFBSQmJuLh4QH8XxD8dr9TUlLs1tOsWbNCLx+73lV5P//8Mw0aNLhl+yA6iS6lqEWLFly4cMHu8txOnTpRv359xowZw/fff8/u3bt59dVXeeqpp2zv/s7OzubChQvFnvK5pn///gQGBnL69GlbW7t27bj//vuZOHEiX3/9NYmJibz11lvs3LmTF1544dbs6G/UrVuXw4cPc+TIEc6cOcOHH35ouwfm2tSdr68v+/btY/v27Zw5c4aoqChOnjxpW0dwcDB16tQhPDyco0ePcuTIESZOnGj4vex/xJUrVwr9EXAr1KxZEycnJz799FPOnDnD999/z8SJE/nhhx9s31OtWrVo2LAhK1eu5IcffuA///kP06ZNs7s0ePjw4XzxxRe88847JCcns379+iJvGszPz+fEiRN638gtpgCRUuPv74+Hhwfx8fG2NmdnZ/7xj39gNpvp168fEydO5PHHH2fatGm2ZT755BPatWtnuyqruEwmE7Nnz6ZKlSq2NkdHR5YvX06rVq34+9//zhNPPMGuXbt4++236dat2x/fyd+ZNm0a9erV4/nnn+epp54iNjaWN954g0qVKtn+Mh40aBBdu3blpZdeonfv3ly4cIEhQ4bY1uHq6srKlSupWrUqzz33HKGhofTq1cvunEhZmTVrFn369Lnl661duzZz587l66+/plu3bowcORInJydGjx7NDz/8QFZWFiaTiXnz5pGbm0vv3r35+9//zrPPPmv3cq2OHTvy1ltvsWXLFnr06MEHH3xQ5JMCjh49SlZW1g2vOJOS0/tApFTFxMSwb9++Ik9qyq313HPP8dBDDzF69OgiP9/Npk2bRk5OTolezCU3pyMQKVWDBg0iKSmJo0ePlvdQ5C514cIFtm3bRlhYWHkP5Y6jAJFSVaVKFWbPns2cOXPKeyhyl3rzzTcJDQ3Vc7BKgaawRETEEB2BiIiIIQoQERExRAEiIiKG6E50A375xUJeXtGPyBARuZ04OjpQtWplQ30VIAbk5eWTm6sAEZG7m6awRETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYokeZlAOTqbxHIGVFb9uRO5kCpIxV86yMs5O+9ruFNTeX9DRLeQ9DpFToN1kZMpnA2cmJVz//mOzcq+U9HCllZqdKTH+0DyaTjkTkzqQAKQfZuVfJUYCIyG1OJ9FFRMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYkiZBUhcXByPP/44fn5+9O/fn1OnTgHQpUsXHnzwQXx9ffH19WXOnDkA5OXlERERgb+/P+3atWPNmjW2dWVlZTF27FhatWpFUFAQO3bssNUuXLjA4MGD8fX1JTg4mEOHDtlqCQkJPP300zz44IP07duXxMTEMtp7EZE7T5kESEJCAjNmzCAyMpL9+/fTsWNHwsLCyMnJ4ccff2T//v0cOnSIQ4cOMWnSJABWrlzJqVOn2LlzJ8uWLWPhwoUkJSUBsGDBAhwcHIiPj2fWrFlMnjyZK1euADBt2jR8fHzYt28fw4YNIzw8nLy8PAoKChg/fjzBwcHs37+fTp06MXXq1LLYfRGRO1KZBMhPP/3EgAEDaN68OY6OjvTv35+kpCS+++477rnnHpydnQv12bx5M0OGDMHd3Z1mzZrRvXt3NmzYAEBsbCwjRozAxcWFwMBA/Pz82LJlCxkZGezatYvQ0FCcnZ3p1asX7u7u7N27lx9++IFz584xcOBAnJ2deeGFF0hISCA5ObksvgIRkTuOU1lspH379rRv3972+csvv6RevXqcPn2a3Nxcevfuzfnz52nfvj0vv/wyVapUISUlBS8vL1sfLy8v9u7dS3p6OmlpaXh7e9vVEhISOH36NJ6enri7uxeqZWVl4eXlhclkAsDBwYEGDRqQkJBgt53iSM+wkmPNLfH34GAyUbOm+80XlDtK2i855BcUlPcwRIrk4uyEp6ebob5lfhL9+PHjREREMGXKFACaN2/OkiVLiIuL4/Lly8yaNQsAi8WC2Wy29TObzVgsFiwWCyaTye6o5VotKysLFxcXu+2ZzWays7OLrFWuXJns7OzS2lURkTtamRyBXBMfH8/YsWOZMGECnTt3BqBPnz62+ujRo/nb3/4G/PqLPycnx1bLzs7Gzc0Ns9lMQUEBVqvVFiLXapUrV7brc63m6upK5cqVsVqtdjWLxYKrq2uJ96NaFWdyc0v+1f3/gx+5y3hWdUEHIFJROTkZP44osyOQzz77jLCwMGbNmkXfvn0BWLduHfv377ct89tQ8Pb2JiUlxVZLTk7G29sbDw8PPD097WpJSUk0btyYRo0acfnyZTIyMgrVrq2v4P//S87Pz+fMmTM0bty4VPdbROROVSYBkpKSwqRJk4iJibEdeQBcvHiROXPmcOnSJS5fvsybb75Jz549AejWrRtLly4lPT2dEydOEBsbS9euXW216OhoLBYL8fHxHDhwgKCgIKpUqcLDDz9MVFQUVquVTZs2cfnyZVq3bk2TJk2oWbMm77//PlarlWXLltGwYUMaNWpUFl+BiMgdp0ymsJYvX052djahoaF27XFxcZw/f57u3buTm5tLt27dGD16NAADBw4kNTWVLl26UKlSJSZMmICPjw8A4eHhRERE0KFDBzw8PIiMjKRGjRoAzJw5k6lTpxIYGEj9+vV5++23bUc1UVFRTJkyhaioKJo2bcrChQvLYvdFRO5IpoICzc6WVFpaJrm5+SXuZzJBzZruTNn2ITm5V0thZFKRuDhVYnbnfly8eEXnQKTCcnJyuH2uwhIRkTuDAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImJImQVIXFwcjz/+OH5+fvTv359Tp04BsGbNGtq3b4+fnx8RERHk5eXZ+sTExBAQEECbNm2IiYmxtefl5REREYG/vz/t2rVjzZo1tlpWVhZjx46lVatWBAUFsWPHDlvtwoULDB48GF9fX4KDgzl06FAZ7LmIyJ2pTAIkISGBGTNmEBkZyf79++nYsSNhYWEcPXqUqKgo3n//fbZt28axY8dYt24dAFu3biUuLo6NGzeydu1aNmzYwJ49ewBYuXIlp06dYufOnSxbtoyFCxeSlJQEwIIFC3BwcCA+Pp5Zs2YxefJkrly5AsC0adPw8fFh3759DBs2jPDwcLvAEhGR4iuTAPnpp58YMGAAzZs3x9HRkf79+5OUlMSmTZvo0aMH9957L9WrV2fYsGGsXbsWgNjYWEJCQqhduzYNGjRgwIABttrmzZsZMmQI7u7uNGvWjO7du7NhwwZbvxEjRuDi4kJgYCB+fn5s2bKFjIwMdu3aRWhoKM7OzvTq1Qt3d3f27t1bFl+BiMgdx6ksNtK+fXvat29v+/zll19Sr149zpw5Q8eOHW3tjRo1IjExEYDk5GT69u1rV9u4cSMAKSkpeHl52WpeXl7s3buX9PR00tLS8Pb2tqslJCRw+vRpPD09cXd3L1R7+OGHS7Q/6RlWcqy5JeoD4GAyUbOm+80XlDtK2i855BcUlPcwRIrk4uyEp6ebob5lfhL9+PHjREREMGXKFCwWC2az2VarXLkyFosFoFDNbDbftGaxWDCZTDg7OxeqZWVl4eLiYjcWs9lMdnZ2qeyniMidrkyOQK6Jj49n7NixTJgwgc6dO7N27VpycnJsdYvFgqurK/DrL/ff1rKzs29Yc3Nzw2w2U1BQgNVqtYXItVrlypXt+vx+nSVRrYozubkl/+pMphJ3kTuAZ1UXdAAiFZWTk/HjiDI7Avnss88ICwtj1qxZtqkpb29vkpOTbcskJyfTuHFjWy0lJaXYNW9vbzw8PPD09LSrJSUl0bhxYxo1asTly5fJyMgoVBMRkZIrkwBJSUlh0qRJxMTE0LlzZ1t7165d2bRpEydPniQtLY1ly5YRHBwMQLdu3Vi1ahWpqamcPXuW1atX29WWLl1Keno6J06cIDY2lq5du9pq0dHRWCwW4uPjOXDgAEFBQVSpUoWHH36YqKgorFYrmzZt4vLly7Ru3bosvgIRkTtOmUxhLV++nOzsbEJDQ+3aP/30U8aNG8fw4cPJzMykZ8+ehISEANClSxcSExPp27cvubm5DBo0iEcffRSAgQMHkpqaSpcuXahUqRITJkzAx8cHgPDwcCIiIujQoQMeHh5ERkZSo0YNAGbOnMnUqVMJDAykfv36vP3223bnS0REpPhMBQWanS2ptLRMcnPzS9zPZIKaNd2Zsu1DcnKvlsLIpCJxcarE7M79uHjxis6BSIXl5ORw+1yFJSIidwYFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETGk2AGyaNGiItvnzZt3ywYjIiK3D6cbFS9cuMChQ4cAWLJkCX/+858pKCiw1a9cucI///lPJkyYULqjFBGRCueGAVK1alWWLFlCWloaOTk5vP7663Z1FxcXRo4cWaoDFBGRiumGAeLi4sLatWsBGDFiBIsXLy6TQYmISMV3wwD5rcWLF2O1Wvn555/Jz8+3q9WrV++WD0xERCq2YgdIbGwsERERZGZm2p0HMZlMHD9+vFQGJyIiFVexAyQ6OpoRI0bQq1cvnJyK3U1ERO5QxU6CCxcuMGTIEBwcdOuIiIiU4D6Qhx9+mF27dpXmWERE5DZS7CMQFxcXQkNDuf/++6levbpdTVdniYjcfYp9BOLl5cXIkSPp0KEDDzzwgN1PSSxfvpypU6faPg8dOpSWLVvi6+uLr68vY8aMsdViYmIICAigTZs2xMTE2Nrz8vL88H0NAAAVcklEQVSIiIjA39+fdu3asWbNGlstKyuLsWPH0qpVK4KCgtixY4etduHCBQYPHoyvry/BwcG2myRFRKTkin0EEhYW9oc2dPXqVRYtWsSiRYt48sknbe3//e9/iY2NpWHDhnbLb926lbi4ODZu3MjVq1cZNGgQrVq1om3btqxcuZJTp06xc+dOzp49y+DBg3nooYfw9vZmwYIFODg4EB8fz8GDBxk7diw7duzA3d2dadOm4ePjw5IlS9iyZQvh4eFs374dR0fHP7RvIiJ3o2IHyOTJk69b+/0d6kWZOXMmqampPPPMM1y9ehWAtLQ0MjMzadCgQaHlY2NjCQkJoXbt2gAMGDCAtWvX0rZtWzZv3kxYWBju7u40a9aM7t27s2HDBsaPH09sbCwrVqzAxcWFwMBA/Pz82LJlC926dWPXrl3MmzcPZ2dnevXqxfLly9m7dy8PP/xwcb8GANIzrORYc0vUB8DBZKJmTfcS95PbW9ovOeT/5tJ3kYrExdkJT083Q32LPYXl6upq92O1Wtm+fTvVqlUrVv+wsDCWLl1KjRo1bG0nTpzA1dWV/v37ExgYyKhRozh37hwAycnJeHl52ZZt1KgRiYmJAKSkpNjVvLy8SEhIID09nbS0NLy9vQvVTp8+jaenJ+7u7oVqIiJScsU+Apk2bVqhtsOHDxMdHV2s/rVq1SrUZrVaadGiBZMnT6ZmzZrMmTOHCRMmsHLlSiwWC2az2bas2WzGYrEAXLdmsVgwmUw4Ozvb1S5dukRWVhYuLi522zebzWRnZxdr/L9VrYozubklvxfGZCpxF7kDeFZ1QQcgUlE5ORm/NeMP3RHYsmVLDh8+bLh/x44d6dixo+1zeHg4AQEBZGZmYjabycnJsdWys7NxdXUFKLLm5uaG2WymoKAAq9VqC5FrtcqVK9v1+f06RUSkZIodPceOHbP7OXz4MDNnzix08rskduzYwbZt22yfrVYrDg4OVKpUCW9vb1JSUmy15ORkGjduDFBkzdvbGw8PDzw9Pe1qSUlJNG7cmEaNGnH58mUyMjIK1UREpOSKHSBPPfWU3U9ISAjx8fFMmjTJ8Mazs7OZNWsWZ86cISsri7lz59KlSxecnZ3p1q0bq1atIjU1lbNnz7J69WqCg4MB6NatG0uXLiU9PZ0TJ04QGxtL165dbbXo6GgsFgvx8fEcOHCAoKAgqlSpwsMPP0xUVBRWq5VNmzZx+fJlWrdubXj8IiJ3s2JPYZ04ceKWbzw4OJiUlBT69etHVlYWHTp04NVXXwWgS5cuJCYm0rdvX3Jzcxk0aBCPPvooAAMHDiQ1NZUuXbpQqVIlJkyYgI+PD/DrNFhERAQdOnTAw8ODyMhI24n7mTNnMnXqVAIDA6lfvz5vv/223fkSEREpPlNBQfFP7509e5ZPPvmEn376iVq1atGtWze7K57uFmlpmeTm5t98wd8xmaBmTXembPuQnNyrpTAyqUhcnCoxu3M/Ll68opPoUmE5OTmU/mW83377LT169GDPnj3k5uayb98+nnjiCfbu3WtowyIicnsr9hRWZGQk06dPp3fv3ra2devWMX/+fD766KNSGZyIiFRcxT4CSUhIoFevXnZtvXr10o14IiJ3qWIHSPXq1fn+++/t2o4dO1bkDYIiInLnK/YU1sCBAxkxYgQDBgygfv36tktrQ0NDS3N8IiJSQRU7QPr3709eXh7r16/HYrFQv359+vXrR0hISGmOT0REKqhiT2Ft3LiRhQsX8vrrr/Ppp58SFBTEihUr2L59e2mOT0REKqhiB8g777zDu+++a7thr3///ixZsoQFCxaU2uBERKTiKnaAXLhwgZYtW9q1tWzZkvPnz9/yQYmISMVX7AC57777+Ne//mXX9tFHH9GkSZNbPigREan4in0S/aWXXmLYsGF88MEH1K1bl//9739cunSJZcuWleb4RESkgip2gPj6+rJ161a++OILLly4QJ06dejYsWOx30goIiJ3lhK9UMrT09PuUSYiInL3Mv4uQxERuaspQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExBAFiIiIGFLmAbJ8+XKmTp1q+7x9+3Y6deqEr68vY8eOJSsry1Zbs2YN7du3x8/Pj4iICPLy8my1mJgYAgICaNOmDTExMbb2vLw8IiIi8Pf3p127dqxZs8ZWy8rKYuzYsbRq1YqgoCB27NhRynsrInLnKrMAuXr1KlFRUURGRtrazp07x+TJk5k3bx5ff/01VquVJUuWAHD06FGioqJ4//332bZtG8eOHWPdunUAbN26lbi4ODZu3MjatWvZsGEDe/bsAWDlypWcOnWKnTt3smzZMhYuXEhSUhIACxYswMHBgfj4eGbNmsXkyZO5cuVKWX0FIiJ3lDILkJkzZ3L06FGeeeYZW9u2bdsICAjA19cXV1dXRo8ebQuJuLg4evTowb333kv16tUZNmwYa9euBSA2NpaQkBBq165NgwYNGDBggK22efNmhgwZgru7O82aNaN79+5s2LDB1m/EiBG4uLgQGBiIn58fW7ZsKauvQETkjuJUVhsKCwujVq1aREdH87///Q+A5ORkvLy8bMs0atSI8+fPk5GRQXJyMh07drSrJSYm2vr17dvXrrZx40YAUlJS7Nbp5eXF3r17SU9PJy0tDW9vb7taQkJCifclPcNKjjW3xP0cTCZq1nQvcT+5vaX9kkN+QUF5D0OkSC7OTnh6uhnqW2ZHILVq1SrUZrFYcHFxsX2uXLmyrd1isWA2m+1qFovFVv9tzWw237RmsVgwmUw4OzsX2U9EREqmzI5AilK5cmWsVqvt87Vf5q6urpjNZnJycuxqrq6uAIVq2dnZN6y5ublhNpspKCjAarXaQuRaraSqVXEmN7fkX53JVOIucgfwrOqCDkCkonJyMn4cUa6X8Xp7e5OcnGz7nJycTO3atXFzcyuy1rhxY1u/lJSUYte8vb3x8PDA09PTrpaUlGTrJyIiJVOuAfLYY48RHx/PN998Q1ZWFjExMQQHBwPQtWtXNm3axMmTJ0lLS2PZsmW2Wrdu3Vi1ahWpqamcPXuW1atX29WWLl1Keno6J06cIDY2lq5du9pq0dHRWCwW4uPjOXDgAEFBQeWz8yIit7lyncKqU6cOb7zxBi+//DIXL17kkUceYezYsQC0aNGCcePGMXz4cDIzM+nZsychISEAdOnShcTERPr27Utubi6DBg3i0UcfBWDgwIGkpqbSpUsXKlWqxIQJE/Dx8QEgPDyciIgIOnTogIeHB5GRkdSoUaN8dl5E5DZnKijQ7GxJpaVlkpubX+J+JhPUrOnOlG0fkpN7tRRGJhWJi1MlZnfux8WLV3QORCosJyeHin8VloiI3FkUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMUICIiYogCREREDFGAiIiIIQoQERExRAEiIiKGKEBERMQQBYiIiBiiABEREUMqRIBMnz6d5s2b4+vri6+vL3369AFgzZo1tG/fHj8/PyIiIsjLy7P1iYmJISAggDZt2hATE2Nrz8vLIyIiAn9/f9q1a8eaNWtstaysLMaOHUurVq0ICgpix44dZbeTIiJ3GKfyHgDAyZMnWbp0KYGBgba2o0ePEhUVxcqVK/H09GT48OGsW7eOvn37snXrVuLi4ti4cSNXr15l0KBBtGrVirZt27Jy5UpOnTrFzp07OXv2LIMHD+ahhx7C29ubBQsW4ODgQHx8PAcPHmTs2LHs2LEDd3f3ctx7EZHbU7kHSEFBASdPnqRp06Z27XFxcfTo0YN7770XgGHDhrF8+XL69u1LbGwsISEh1K5dG4ABAwawdu1a2rZty+bNmwkLC8Pd3Z1mzZrRvXt3NmzYwPjx44mNjWXFihW4uLgQGBiIn58fW7Zs4emnny7RmNMzrORYc0u8rw4mEzVrKqzuNmm/5JBfUFDewxApkouzE56ebob6lvsU1tmzZ7l69SoTJ04kICCA559/noSEBJKTk/Hy8rIt16hRIxITEwFuWEtJSbGreXl5kZCQQHp6OmlpaXh7exeqiYhIyZX7Ecgvv/xC69atCQ8P589//jNLly4lNDSUunXrYjabbctVrlwZi8UCgMVisauZzeab1iwWCyaTCWdnZ7vapUuXSjzmalWcyc0t+VdnMpW4i9wBPKu6oAMQqaicnIwfR5T7Ecj999/Pe++9x1/+8hecnZ0ZNWoUFy9exMHBgZycHNtyFosFV1dX4Ndf/L+tZWdn37Dm5uaG2WymoKAAq9VaqCYiIiVX7gHy7bff8vHHH9s+5+fnk5eXR5UqVUhOTra1Jycn07hxYwC8vb1JSUkpds3b2xsPDw88PT3taklJSbZ+IiJSMuUeII6OjsyZM4fvv/8eq9XK/Pnzadq0KX/729/YtGkTJ0+eJC0tjWXLlhEcHAxAt27dWLVqFampqZw9e5bVq1fb1ZYuXUp6ejonTpwgNjaWrl272mrR0dFYLBbi4+M5cOAAQUFB5bbvIiK3s3I/B+Lr68tLL71EWFgYaWlptGrVijfffJO6desybtw4hg8fTmZmJj179iQkJASALl26kJiYSN++fcnNzWXQoEE8+uijAAwcOJDU1FS6dOlCpUqVmDBhAj4+PgCEh4cTERFBhw4d8PDwIDIykho1apTbvouI3M5MBQU6vVdSaWmZ5Obml7ifyQQ1a7ozZduH5OReLYWRSUXi4lSJ2Z37cfHiFZ1ElwrLycnh9r2MV0REbk8KEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAxRgIiIiCEKEBERMUQBIiIihihARETEEAWIiIgYogARERFDFCAiImKIAkRERAy56wLkwIED9OjRgwcffJDBgwdz8eLF8h6SiMht6a4KkOzsbMaMGcOYMWPYv38/jRo1Ys6cOeU9LBGR29JdFSDx8fHUrl2bzp074+zszLhx4/jss8/Iysoq76GJiNx2nMp7AGUpJSUFLy8v22cPDw9cXV05ffo0Pj4+xV6PJScP69W8Em/fwfTr/3p51MKal1vi/nJ7cXb89Z9XVnYu+QVlv30TYDKV/XalfBQUgJH/zJwrOeJpcJt3VYBkZWXh4uJi11a5cmWys7NLtJ56dar+oXEM8+/0h/rL7eWeBkb/eYpUbHfVFFblypWxWq12bRaLBVdX13IakYjI7euuChBvb2+Sk5Ntny9fvkxmZib33HNP+Q1KROQ2dVcFSEBAAKmpqWzZsgWr1cqbb75JUFAQZrO5vIcmInLbMRUUFJTD6b3y89133zF9+nROnz5Nq1atmDdvHtWrVy/vYYmI3HbuugAREZFb466awhIRkVtHASIiIoYoQERExBAFiIiIGKIAERERQxQgUqr0+Hwpa8uXL2fq1KnlPYy7ggJESo0eny9l6erVq0RFRREZGVneQ7lrKECk1Ojx+VKWZs6cydGjR3nmmWfKeyh3DQWIlJobPT5f5FYLCwtj6dKl1KhRo7yHctdQgEipuVWPzxcpjlq1apX3EO46ChApNXp8vsidTQEipUaPzxe5sylApNTo8fkidzYFiJQas9nMokWLWLx4MW3atOHMmTNERESU97BE5BbR49xFRMQQHYGIiIghChARETFEASIiIoYoQERExBAFiIiIGKIAERERQxQgIiJiiAJEpJTFx8czdOhQ2rRpg7+/PyEhIezatQuASZMm8eqrr5bzCEWMUYCIlKINGzYQHh7Os88+y65du9izZw/PPPMMo0eP5osvvijv4Yn8IU7lPQCRO1V2djazZs1i9uzZdO7c2dbeq1cv0tLSSEpKslv+l19+YdasWXz77bdcvHiROnXqMGHCBDp16kR+fj6zZ89my5Yt5Ofn06xZM6ZNm4a3tzdJSUlMmzaNEydOUK1aNTp16sTEiRNxdHQs612Wu4yOQERKycGDB8nJyeGRRx4pVBs0aBCDBw+2a5s/fz6ZmZls3ryZAwcOEBwczGuvvQbAtm3b2LdvH59++ilfffUVtWvXJioqCoC5c+fSpk0bvvnmG1atWsWWLVvYvXt3qe+fiI5ARErJzz//TLVq1ahUqVKxlh89ejTOzs44OzuTmpqKm5sb586dA6Bq1ar89NNPrF27lkceeYRZs2bh4OBgq3399dc0bdqUwMBAvvjiC1tNpDTpvzKRUlKrVi0uX77M1atXC9UyMjKwWCx2befPnyc0NJS2bdvy4osvcuTIEa496zQwMJCIiAi2bt1K9+7d6dq1Kzt27ABg+vTptGzZkjfeeIOAgABCQ0NtwSNSmhQgIqXE19cXs9nMl19+Wai2aNEi+vXrZ9c2fvx42rVrx969e1mzZg19+/a11c6cOcN9993HP//5T/bu3ctTTz3FuHHjsFqtHD9+nFGjRrF9+3Y++eQTMjMzWbhwYanvn4gCRKSUODs7M2HCBKZPn8727du5evUq2dnZ/Otf/2LVqlWMHTvWbvmMjAxcXFxwcHDg7NmzxMTEAGC1WomPj2fUqFH8+OOPuLm5UbVqVapUqYKTkxPz589n4cKFWK1WatasiaOjIx4eHuWxy3KX0TkQkVL09NNP4+7uzj/+8Q+mTJlCfn4+Pj4+LF68mLZt2/LZZ5/Zlr12xVZUVBS1atWiX79+HD9+nB9++IE+ffqQnJzMM888Q2ZmJt7e3kRHR+Pg4MAbb7zBK6+8Qtu2bTGZTHTo0IGwsLBy3Gu5W+iFUiIiYoimsERExBAFiIiIGKIAERERQxQgIiJiiAJEREQMUYCIiIghChARETFEASIiIoYoQERExJD/B9I8XKIsZaCsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(5, 5), dpi=80)\n",
    "plt.grid(color='b', linestyle='-', linewidth=0.2)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
    "sns.countplot('Class', data=df,palette='Set2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for a in df.columns[1:]:\n",
    "    if df[a].isnull().sum() > 0 :\n",
    "#         print(a)\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import (RandomUnderSampler, \n",
    "#                                      ClusterCentroids,\n",
    "#                                      TomekLinks,\n",
    "#                                      NeighbourhoodCleaningRule,\n",
    "#                                      NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "# from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# # RobustScaler is less prone to outliers.\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# rob_scaler = RobustScaler()\n",
    "# minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# # df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "# # df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "# df['scaled_amount'] = minmax_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "# df['scaled_time'] = minmax_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "# df.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "\n",
    "# scaled_amount = df['scaled_amount']\n",
    "# scaled_time = df['scaled_time']\n",
    "\n",
    "# df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "# df.insert(0, 'scaled_amount', scaled_amount)\n",
    "# df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# # Amount and Time are Scaled!\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128627.0</td>\n",
       "      <td>-0.865285</td>\n",
       "      <td>-0.979506</td>\n",
       "      <td>2.587540</td>\n",
       "      <td>-2.781144</td>\n",
       "      <td>-0.887336</td>\n",
       "      <td>-0.579689</td>\n",
       "      <td>-0.976755</td>\n",
       "      <td>0.132058</td>\n",
       "      <td>-1.658263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106978</td>\n",
       "      <td>-0.010528</td>\n",
       "      <td>-0.211955</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.358237</td>\n",
       "      <td>-0.209483</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70536.0</td>\n",
       "      <td>-2.271755</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>-2.589055</td>\n",
       "      <td>2.230778</td>\n",
       "      <td>-4.278983</td>\n",
       "      <td>0.388610</td>\n",
       "      <td>0.102485</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>-1.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096342</td>\n",
       "      <td>0.658399</td>\n",
       "      <td>1.711676</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>0.538591</td>\n",
       "      <td>-0.193529</td>\n",
       "      <td>0.258194</td>\n",
       "      <td>0.247269</td>\n",
       "      <td>824.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166831.0</td>\n",
       "      <td>-2.027135</td>\n",
       "      <td>-1.131890</td>\n",
       "      <td>-1.135194</td>\n",
       "      <td>1.086963</td>\n",
       "      <td>-0.010547</td>\n",
       "      <td>0.423797</td>\n",
       "      <td>3.790880</td>\n",
       "      <td>-1.155595</td>\n",
       "      <td>-0.063434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315105</td>\n",
       "      <td>0.575520</td>\n",
       "      <td>0.490842</td>\n",
       "      <td>0.756502</td>\n",
       "      <td>-0.142685</td>\n",
       "      <td>-0.602777</td>\n",
       "      <td>0.508712</td>\n",
       "      <td>-0.091646</td>\n",
       "      <td>634.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75987.0</td>\n",
       "      <td>0.531678</td>\n",
       "      <td>-1.108844</td>\n",
       "      <td>0.276972</td>\n",
       "      <td>0.386453</td>\n",
       "      <td>-1.038906</td>\n",
       "      <td>-0.810526</td>\n",
       "      <td>0.395582</td>\n",
       "      <td>-0.322635</td>\n",
       "      <td>0.068460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>-0.824566</td>\n",
       "      <td>-0.174821</td>\n",
       "      <td>0.479535</td>\n",
       "      <td>-0.094335</td>\n",
       "      <td>0.698329</td>\n",
       "      <td>-0.130716</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>386.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136908.0</td>\n",
       "      <td>1.878626</td>\n",
       "      <td>0.162765</td>\n",
       "      <td>-0.167433</td>\n",
       "      <td>3.465196</td>\n",
       "      <td>0.197332</td>\n",
       "      <td>1.157212</td>\n",
       "      <td>-0.676783</td>\n",
       "      <td>0.473890</td>\n",
       "      <td>-0.386278</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.217428</td>\n",
       "      <td>-0.785738</td>\n",
       "      <td>0.406279</td>\n",
       "      <td>-0.056071</td>\n",
       "      <td>-0.560484</td>\n",
       "      <td>-0.388620</td>\n",
       "      <td>-0.012717</td>\n",
       "      <td>-0.038421</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0  128627.0 -0.865285 -0.979506  2.587540 -2.781144 -0.887336 -0.579689   \n",
       "1   70536.0 -2.271755 -0.457655 -2.589055  2.230778 -4.278983  0.388610   \n",
       "2  166831.0 -2.027135 -1.131890 -1.135194  1.086963 -0.010547  0.423797   \n",
       "3   75987.0  0.531678 -1.108844  0.276972  0.386453 -1.038906 -0.810526   \n",
       "4  136908.0  1.878626  0.162765 -0.167433  3.465196  0.197332  1.157212   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0 -0.976755  0.132058 -1.658263  ... -0.106978 -0.010528 -0.211955  0.021026   \n",
       "1  0.102485  0.813128 -1.092921  ...  1.096342  0.658399  1.711676  0.333540   \n",
       "2  3.790880 -1.155595 -0.063434  ... -0.315105  0.575520  0.490842  0.756502   \n",
       "3  0.395582 -0.322635  0.068460  ...  0.000589 -0.824566 -0.174821  0.479535   \n",
       "4 -0.676783  0.473890 -0.386278  ... -0.217428 -0.785738  0.406279 -0.056071   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.358237 -0.209483  0.062051  0.074730    8.00      0  \n",
       "1  0.538591 -0.193529  0.258194  0.247269  824.83      1  \n",
       "2 -0.142685 -0.602777  0.508712 -0.091646  634.30      1  \n",
       "3 -0.094335  0.698329 -0.130716  0.083227  386.60      0  \n",
       "4 -0.560484 -0.388620 -0.012717 -0.038421    5.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "# Lets shuffle the data before creating the subsamples\n",
    "df_copy = df.copy()\n",
    "# df_copy = df_copy.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df_copy.loc[df_copy['Class'] == 1]\n",
    "non_fraud_df = df_copy.loc[df['Class'] == 0][:492]\n",
    "non_fraud_df = df_copy.loc[df_copy['Class'] == 0].sample(n=492,random_state=1)\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "df_new = normal_distributed_df.sample(frac=1, random_state=1)\n",
    "df_new = df_new.reset_index()\n",
    "df_new = df_new.drop('index', axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2662d259898>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(5, 5), dpi=80)\n",
    "plt.grid(color='b', linestyle='-', linewidth=0.2)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
    "sns.countplot('Class', data=df_new,palette='Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.drop('Class', axis=1)\n",
    "# y = df['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = df_new.drop('Class', axis=1)\n",
    "y_new = df_new['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    492\n",
       "0    492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "# # RobustScaler is less prone to outliers.\n",
    "\n",
    "# std_scaler = StandardScaler()\n",
    "# rob_scaler = RobustScaler()\n",
    "# minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# X_neww = minmax_scaler.fit_transform(X_new)\n",
    "# X_new = pd.DataFrame(X_neww, columns=X_new.columns)\n",
    "# X_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # SKLearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "n_tree = 10\n",
    "clf = RandomForestClassifier(random_state=1,n_estimators=n_tree, max_features='sqrt')\n",
    "clf.fit(X_new,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_DT = DecisionTreeClassifier(random_state=1)\n",
    "clf_DT.fit(X_new,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_skenarion_1 (clf,X,y,kfolds):\n",
    "    CV_SKLearn = kfold_cross_validation(clf,X,y,n_fold=kfolds,n_seed=1)\n",
    "    df_result = pd.DataFrame(data= CV_SKLearn, columns=['Akurasi','Sensitivity','Specifity','precision','recall','f1_score','Waktu'])\n",
    "\n",
    "    df_result.insert(loc=0, column='No', value=list(range(1,df_result.shape[0]+1)))\n",
    "    df_result = df_result.set_index('No')\n",
    "\n",
    "    del df_result.index.name\n",
    "\n",
    "    df_result = df_result.append(df_result.describe()[1:2])\n",
    "    \n",
    "    return df_result\n",
    "# result_SKLearn = result_SKLearn.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Akurasi</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specifity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Waktu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.062585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.960396</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.046798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.962162</td>\n",
       "      <td>0.046878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913265</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.941860</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.905028</td>\n",
       "      <td>0.046879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.933673</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.891089</td>\n",
       "      <td>0.932642</td>\n",
       "      <td>0.046878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.932653</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>0.969329</td>\n",
       "      <td>0.966738</td>\n",
       "      <td>0.895139</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.050004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Akurasi  Sensitivity  Specifity  precision    recall  f1_score  \\\n",
       "1     0.918367     0.861702   0.970588   0.964286  0.861702  0.910112   \n",
       "2     0.933673     0.915094   0.955556   0.960396  0.915094  0.937198   \n",
       "3     0.964286     0.936842   0.990099   0.988889  0.936842  0.962162   \n",
       "4     0.913265     0.870968   0.951456   0.941860  0.870968  0.905028   \n",
       "5     0.933673     0.891089   0.978947   0.978261  0.891089  0.932642   \n",
       "mean  0.932653     0.895139   0.969329   0.966738  0.895139  0.929429   \n",
       "\n",
       "         Waktu  \n",
       "1     0.062585  \n",
       "2     0.046798  \n",
       "3     0.046878  \n",
       "4     0.046879  \n",
       "5     0.046878  \n",
       "mean  0.050004  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_SKLearn = run_skenarion_1(clf,X_new,y_new,5)\n",
    "result_SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Akurasi</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specifity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Waktu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.862245</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.868132</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.031254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.882653</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.890995</td>\n",
       "      <td>0.015627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923469</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.920792</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.926316</td>\n",
       "      <td>0.921466</td>\n",
       "      <td>0.031252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882653</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.864078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.031251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.940594</td>\n",
       "      <td>0.922330</td>\n",
       "      <td>0.031253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.893878</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.887947</td>\n",
       "      <td>0.888388</td>\n",
       "      <td>0.899471</td>\n",
       "      <td>0.893685</td>\n",
       "      <td>0.028128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Akurasi  Sensitivity  Specifity  precision    recall  f1_score  \\\n",
       "1     0.862245     0.840426   0.882353   0.868132  0.840426  0.854054   \n",
       "2     0.882653     0.886792   0.877778   0.895238  0.886792  0.890995   \n",
       "3     0.923469     0.926316   0.920792   0.916667  0.926316  0.921466   \n",
       "4     0.882653     0.903226   0.864078   0.857143  0.903226  0.879581   \n",
       "5     0.918367     0.940594   0.894737   0.904762  0.940594  0.922330   \n",
       "mean  0.893878     0.899471   0.887947   0.888388  0.899471  0.893685   \n",
       "\n",
       "         Waktu  \n",
       "1     0.031254  \n",
       "2     0.015627  \n",
       "3     0.031252  \n",
       "4     0.031251  \n",
       "5     0.031253  \n",
       "mean  0.028128  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_SKLearn = run_skenarion_1(clf_DT,X_new,y_new,5)\n",
    "result_SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "    \n",
    "clf_RF = RandomForestClassifier(random_state=1,n_estimators=100)\n",
    "clf_AB = AdaBoostClassifier(random_state=1,n_estimators=100)\n",
    "clf_B = BaggingClassifier(random_state=1,n_estimators=100)\n",
    "clf_ET = ExtraTreesClassifier(random_state=1,n_estimators=100)\n",
    "clf_GB = GradientBoostingClassifier(random_state=1,n_estimators=50)\n",
    "\n",
    "##skenario \n",
    "skenario_1 = {}\n",
    "skenario_1['1'] = clf_RF,\n",
    "skenario_1['2'] = clf_AB,\n",
    "skenario_1['3'] = clf_B,\n",
    "skenario_1['4'] = clf_ET,\n",
    "skenario_1['5'] = clf_GB,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                       warm_start=False),)\n",
      "(AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=100, random_state=1),)\n",
      "(BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=100,\n",
      "                  n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                  warm_start=False),)\n",
      "(ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                     n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
      "                     warm_start=False),)\n",
      "(GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=1, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False),)\n"
     ]
    }
   ],
   "source": [
    "for i in skenario_1:\n",
    "    \n",
    "    if isinstance(skenario_1[i], tuple) :\n",
    "        clf_skenario = skenario_1[i][0]\n",
    "    else :\n",
    "        clf_skenario = skenario_1[i]\n",
    "    print(skenario_1[i])\n",
    "\n",
    "    \n",
    "    result_SKLearn = run_skenarion_1(clf_skenario,X_new,y_new,5)\n",
    "#     print(result_SKLearn)\n",
    "    \n",
    "    nama_file = 'hasil/skenario1/random_ensemble/komposisi999.csv'\n",
    "    nama_file = nama_file.replace('999',str(i))\n",
    "\n",
    "    result_SKLearn.to_csv(nama_file, sep=';',index=False)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Akurasi</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specifity</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Waktu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.903457</td>\n",
       "      <td>0.983162</td>\n",
       "      <td>0.982676</td>\n",
       "      <td>0.903457</td>\n",
       "      <td>0.941141</td>\n",
       "      <td>0.442282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941837</td>\n",
       "      <td>0.922023</td>\n",
       "      <td>0.961668</td>\n",
       "      <td>0.959345</td>\n",
       "      <td>0.922023</td>\n",
       "      <td>0.940110</td>\n",
       "      <td>0.723951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.909382</td>\n",
       "      <td>0.967252</td>\n",
       "      <td>0.965240</td>\n",
       "      <td>0.909382</td>\n",
       "      <td>0.936269</td>\n",
       "      <td>1.824568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.888951</td>\n",
       "      <td>0.981260</td>\n",
       "      <td>0.980257</td>\n",
       "      <td>0.888951</td>\n",
       "      <td>0.931993</td>\n",
       "      <td>0.231202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943878</td>\n",
       "      <td>0.913342</td>\n",
       "      <td>0.972970</td>\n",
       "      <td>0.972288</td>\n",
       "      <td>0.913342</td>\n",
       "      <td>0.941571</td>\n",
       "      <td>0.239869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Akurasi  Sensitivity  Specifity  precision    recall  f1_score     Waktu\n",
       "0  0.943878     0.903457   0.983162   0.982676  0.903457  0.941141  0.442282\n",
       "1  0.941837     0.922023   0.961668   0.959345  0.922023  0.940110  0.723951\n",
       "2  0.938776     0.909382   0.967252   0.965240  0.909382  0.936269  1.824568\n",
       "3  0.935714     0.888951   0.981260   0.980257  0.888951  0.931993  0.231202\n",
       "4  0.943878     0.913342   0.972970   0.972288  0.913342  0.941571  0.239869"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame()\n",
    "for i in skenario_1:\n",
    "    nama_file = 'hasil/skenario1/random_ensemble/komposisi999.csv'\n",
    "    nama_file = nama_file.replace('999',str(i))\n",
    "    df_komposisi = pd.read_csv(nama_file,sep=\";\")\n",
    "    df_result = df_result.append(df_komposisi.iloc[5:,:])\n",
    "    \n",
    "df_result.insert(loc=0, column='No', value=list(range(df_result.shape[0])))\n",
    "df_result = df_result.set_index('No')\n",
    "\n",
    "del df_result.index.name\n",
    "\n",
    "df_result.to_csv('hasil/skenario1/random_ensemble/result.csv', sep=';',index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = clf.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# fitur_importance =[]\n",
    "# for f in range(X_new.shape[1]):\n",
    "#     if  importances[indices[f]] > 0 :\n",
    "#         fitur_importance.append([X_new.columns[indices[f]],importances[indices[f]]])\n",
    "#         print(\"%2d) %-*s %f\" % (f + 1, 30,\n",
    "#         X_new.columns[indices[f]],\n",
    "#         importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FI = pd.DataFrame(data=fitur_importance,columns=['fitur','value'])\n",
    "# # np.array(df_FI['fitur'])\n",
    "# df_FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = StringIO()  \n",
    "# tree.export_graphviz(clf.estimators_[8], out_file=dot_data,  \n",
    "#                          feature_names=X_new.columns)  \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = StringIO()  \n",
    "# tree.export_graphviz(clf_DT,out_file=dot_data,feature_names=X_new.columns)  \n",
    "# graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "RandomizedSearchCV took 28.57 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.945 (std: 0.004)\n",
      "Parameters: {'n_estimators': 100, 'max_depth': 11}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.945 (std: 0.002)\n",
      "Parameters: {'n_estimators': 100, 'max_depth': 9}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.944 (std: 0.004)\n",
      "Parameters: {'n_estimators': 100, 'max_depth': 15}\n",
      "\n",
      "GridSearchCV took 28.55 seconds for 20 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.945 (std: 0.004)\n",
      "Parameters: {'max_depth': 11, 'n_estimators': 100}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.945 (std: 0.002)\n",
      "Parameters: {'max_depth': 9, 'n_estimators': 100}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.944 (std: 0.004)\n",
      "Parameters: {'max_depth': 15, 'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(random_state=1,n_jobs=-1)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [5,9,11,15 ],\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": sp_randint(1, 11),\n",
    "#               \"min_samples_split\": sp_randint(2, 11),\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_new, y_new)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [5,9,11,15 ],\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": [1, 3, 10],\n",
    "#               \"min_samples_split\": [2, 3, 10],\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\new folder (2)\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 5 is smaller than n_iter=20. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 12.12 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.936 (std: 0.012)\n",
      "Parameters: {'n_estimators': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.933 (std: 0.012)\n",
      "Parameters: {'n_estimators': 75}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.933 (std: 0.020)\n",
      "Parameters: {'n_estimators': 100}\n",
      "\n",
      "GridSearchCV took 13.26 seconds for 5 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.936 (std: 0.012)\n",
      "Parameters: {'n_estimators': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.933 (std: 0.012)\n",
      "Parameters: {'n_estimators': 75}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.933 (std: 0.020)\n",
      "Parameters: {'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = AdaBoostClassifier(random_state=1)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": sp_randint(1, 11),\n",
    "#               \"min_samples_split\": sp_randint(2, 11),\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_new, y_new)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": [1, 3, 10],\n",
    "#               \"min_samples_split\": [2, 3, 10],\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "RandomizedSearchCV took 49.48 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.938 (std: 0.011)\n",
      "Parameters: {'n_estimators': 50, 'max_depth': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.937 (std: 0.012)\n",
      "Parameters: {'n_estimators': 75, 'max_depth': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.937 (std: 0.010)\n",
      "Parameters: {'n_estimators': 100, 'max_depth': 3}\n",
      "\n",
      "GridSearchCV took 62.23 seconds for 25 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.938 (std: 0.011)\n",
      "Parameters: {'max_depth': 3, 'n_estimators': 50}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.937 (std: 0.012)\n",
      "Parameters: {'max_depth': 3, 'n_estimators': 75}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.937 (std: 0.010)\n",
      "Parameters: {'max_depth': 3, 'n_estimators': 100}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = GradientBoostingClassifier(random_state=1)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3,5,9,11,15 ],\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": sp_randint(1, 11),\n",
    "#               \"min_samples_split\": sp_randint(2, 11),\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False,random_state=1)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_new, y_new)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3,5,9,11,15 ],\n",
    "              'n_estimators' : [10,25,50,75,100],\n",
    "#               \"max_features\": [1, 3, 10],\n",
    "#               \"min_samples_split\": [2, 3, 10],\n",
    "#               \"bootstrap\": [True, False],\n",
    "#               \"criterion\": [\"gini\", \"entropy\"]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, iid=False)\n",
    "start = time()\n",
    "grid_search.fit(X_new, y_new)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
